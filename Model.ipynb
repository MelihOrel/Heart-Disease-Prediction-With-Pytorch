{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0    1   39        4.0              0         0.0     0.0                0   \n",
       "1    0   46        2.0              0         0.0     0.0                0   \n",
       "2    1   48        1.0              1        20.0     0.0                0   \n",
       "3    0   61        3.0              1        30.0     0.0                0   \n",
       "4    0   46        3.0              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('heart_disease.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex  age  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  prevalentHyp  \\\n",
       "0    1   39              0         0.0     0.0                0             0   \n",
       "1    0   46              0         0.0     0.0                0             0   \n",
       "2    1   48              1        20.0     0.0                0             0   \n",
       "3    0   61              1        30.0     0.0                0             1   \n",
       "4    0   46              1        23.0     0.0                0             0   \n",
       "\n",
       "   diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  TenYearCHD  \n",
       "0         0    195.0  106.0   70.0  26.97       80.0     77.0           0  \n",
       "1         0    250.0  121.0   81.0  28.73       95.0     76.0           0  \n",
       "2         0    245.0  127.5   80.0  25.34       75.0     70.0           0  \n",
       "3         0    225.0  150.0   95.0  28.58       65.0    103.0           1  \n",
       "4         0    285.0  130.0   84.0  23.10       85.0     85.0           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We must drop education column \n",
    "df.drop(['education'],axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex                0\n",
       "age                0\n",
       "currentSmoker      0\n",
       "cigsPerDay         0\n",
       "BPMeds             0\n",
       "prevalentStroke    0\n",
       "prevalentHyp       0\n",
       "diabetes           0\n",
       "totChol            0\n",
       "sysBP              0\n",
       "diaBP              0\n",
       "BMI                0\n",
       "heartRate          0\n",
       "glucose            0\n",
       "TenYearCHD         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find NAN\n",
    "#NAN_df = df[df.isna().any(axis=1)]\n",
    "#display(nan_df)\n",
    "# drop NAN\n",
    "df = df.dropna(axis=0)\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test/Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('TenYearCHD',axis=1).values\n",
    "y = df['TenYearCHD'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3000, 14])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape # we have 14 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a model class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,input_layer=14,h1=128,h2=64,h3=32,h4=16,h5=8,output_layer=2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_layer,h1)      #input layers\n",
    "        self.fc2 = nn.Linear(h1, h2)              #hidden layers\n",
    "        self.fc3 = nn.Linear(h2, h3)              #hidden layers\n",
    "        self.fc4 = nn.Linear(h3, h4)              #hidden layers\n",
    "        self.fc5 = nn.Linear(h4, h5)              #hidden layers\n",
    "        self.out = nn.Linear(h5, output_layer)    #output layers\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (fc1): Linear(in_features=14, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc4): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (fc5): Linear(in_features=16, out_features=8, bias=True)\n",
       "  (out): Linear(in_features=8, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model = Model()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss and optimizations\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10  loss: 0.65212619\n",
      "epoch: 20  loss: 0.49752092\n",
      "epoch: 30  loss: 0.44410676\n",
      "epoch: 40  loss: 0.42755091\n",
      "epoch: 50  loss: 0.42508802\n",
      "epoch: 60  loss: 0.42426425\n",
      "epoch: 70  loss: 0.42303914\n",
      "epoch: 80  loss: 0.42213219\n",
      "epoch: 90  loss: 0.42126563\n",
      "epoch: 100  loss: 0.42046964\n"
     ]
    }
   ],
   "source": [
    "#Train \n",
    "epochs = 100\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i+=1\n",
    "    loss = criterion(model.forward(X_train), y_train)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    \n",
    "    if i%10 == 0:\n",
    "        print(f'epoch: {i:2}  loss: {loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### plot\n",
    "plt.plot(range(epochs), losses)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. tensor([2.7739, 1.0503])                0\n",
      " 2. tensor([3.0431, 1.1390])                0\n",
      " 3. tensor([3.3787, 1.3867])                0\n",
      " 4. tensor([2.9444, 1.0887])                0\n",
      " 5. tensor([2.0394, 0.6700])                1\n",
      " 6. tensor([2.6479, 1.0217])                0\n",
      " 7. tensor([2.6683, 1.0635])                1\n",
      " 8. tensor([2.6232, 0.9696])                0\n",
      " 9. tensor([2.3178, 0.8110])                0\n",
      "10. tensor([3.1304, 1.1429])                0\n",
      "11. tensor([1.7518, 0.5528])                0\n",
      "12. tensor([2.9233, 1.1271])                0\n",
      "13. tensor([2.3505, 0.8402])                0\n",
      "14. tensor([2.5231, 0.9345])                0\n",
      "15. tensor([2.4965, 0.8927])                0\n",
      "16. tensor([2.7768, 1.0181])                0\n",
      "17. tensor([2.8434, 1.0691])                0\n",
      "18. tensor([2.7159, 1.0272])                0\n",
      "19. tensor([2.1618, 0.7485])                0\n",
      "20. tensor([2.6099, 0.9315])                0\n",
      "21. tensor([3.2297, 1.2528])                0\n",
      "22. tensor([3.6906, 1.5010])                0\n",
      "23. tensor([2.8553, 1.1594])                0\n",
      "24. tensor([3.0122, 1.1673])                0\n",
      "25. tensor([2.6796, 1.0086])                0\n",
      "26. tensor([3.1334, 1.2285])                0\n",
      "27. tensor([2.5214, 0.8989])                0\n",
      "28. tensor([1.9980, 0.7181])                1\n",
      "29. tensor([2.2743, 0.7849])                0\n",
      "30. tensor([2.9907, 1.0996])                0\n",
      "31. tensor([2.9781, 1.1304])                0\n",
      "32. tensor([2.7068, 1.0830])                0\n",
      "33. tensor([2.3351, 0.7856])                0\n",
      "34. tensor([2.5392, 0.9300])                0\n",
      "35. tensor([3.1030, 1.1475])                0\n",
      "36. tensor([3.0876, 1.1285])                0\n",
      "37. tensor([2.5736, 0.9683])                1\n",
      "38. tensor([2.5732, 0.8941])                0\n",
      "39. tensor([2.9309, 1.1294])                0\n",
      "40. tensor([3.7909, 1.4864])                0\n",
      "41. tensor([2.7422, 1.0255])                0\n",
      "42. tensor([2.7530, 1.0431])                0\n",
      "43. tensor([2.3610, 0.8176])                0\n",
      "44. tensor([2.7232, 0.9661])                0\n",
      "45. tensor([2.7847, 0.9979])                0\n",
      "46. tensor([2.3602, 0.8542])                0\n",
      "47. tensor([2.4171, 0.8580])                1\n",
      "48. tensor([3.4614, 1.4187])                0\n",
      "49. tensor([2.8923, 1.1066])                0\n",
      "50. tensor([2.4102, 0.8595])                0\n",
      "51. tensor([2.6225, 0.9467])                0\n",
      "52. tensor([2.7874, 1.0396])                0\n",
      "53. tensor([3.4085, 1.3218])                0\n",
      "54. tensor([2.3269, 0.8423])                0\n",
      "55. tensor([2.9552, 1.1487])                0\n",
      "56. tensor([2.6494, 1.0115])                0\n",
      "57. tensor([3.6318, 1.4927])                0\n",
      "58. tensor([2.3300, 0.8196])                1\n",
      "59. tensor([2.7502, 0.9905])                0\n",
      "60. tensor([2.0658, 0.7412])                1\n",
      "61. tensor([2.6676, 0.9720])                0\n",
      "62. tensor([2.8549, 1.0939])                0\n",
      "63. tensor([2.6161, 0.9638])                0\n",
      "64. tensor([2.6819, 0.9748])                0\n",
      "65. tensor([3.2498, 1.2748])                0\n",
      "66. tensor([2.5918, 0.9034])                0\n",
      "67. tensor([2.6413, 0.9582])                0\n",
      "68. tensor([3.4965, 1.3861])                0\n",
      "69. tensor([3.0891, 1.2430])                0\n",
      "70. tensor([2.2624, 0.7761])                0\n",
      "71. tensor([2.5436, 0.9062])                0\n",
      "72. tensor([2.6722, 1.0207])                0\n",
      "73. tensor([2.7172, 1.0084])                0\n",
      "74. tensor([2.0775, 0.7235])                0\n",
      "75. tensor([2.8392, 1.0245])                0\n",
      "76. tensor([2.8942, 1.1096])                1\n",
      "77. tensor([2.7348, 1.0177])                0\n",
      "78. tensor([2.7461, 1.0748])                0\n",
      "79. tensor([2.7330, 1.0484])                0\n",
      "80. tensor([2.9415, 1.1337])                0\n",
      "81. tensor([2.5170, 0.9489])                0\n",
      "82. tensor([2.6682, 0.9200])                0\n",
      "83. tensor([3.2673, 1.2892])                1\n",
      "84. tensor([2.3969, 0.9810])                1\n",
      "85. tensor([2.6793, 0.9763])                0\n",
      "86. tensor([2.6156, 1.0187])                0\n",
      "87. tensor([2.9356, 1.1528])                1\n",
      "88. tensor([2.6349, 0.9977])                0\n",
      "89. tensor([2.7932, 1.0773])                0\n",
      "90. tensor([3.1172, 1.1795])                0\n",
      "91. tensor([2.6327, 1.0011])                1\n",
      "92. tensor([3.9484, 1.6872])                1\n",
      "93. tensor([2.9460, 1.1359])                0\n",
      "94. tensor([2.4644, 0.9466])                0\n",
      "95. tensor([2.2206, 0.8646])                1\n",
      "96. tensor([2.2664, 0.8625])                0\n",
      "97. tensor([2.7983, 1.1015])                0\n",
      "98. tensor([2.3623, 0.8643])                0\n",
      "99. tensor([2.0408, 0.8355])                0\n",
      "100. tensor([2.9658, 1.1710])                1\n",
      "101. tensor([3.3604, 1.3564])                1\n",
      "102. tensor([2.9560, 1.1273])                0\n",
      "103. tensor([2.6113, 0.9428])                0\n",
      "104. tensor([3.1801, 1.2176])                0\n",
      "105. tensor([2.8577, 1.1238])                0\n",
      "106. tensor([2.7455, 1.0835])                0\n",
      "107. tensor([2.4719, 0.9580])                1\n",
      "108. tensor([2.6496, 0.9499])                0\n",
      "109. tensor([3.4658, 1.4182])                0\n",
      "110. tensor([2.5465, 0.9116])                0\n",
      "111. tensor([2.7553, 1.0301])                0\n",
      "112. tensor([3.0909, 1.0977])                0\n",
      "113. tensor([2.8082, 1.0733])                0\n",
      "114. tensor([2.9226, 1.1542])                0\n",
      "115. tensor([2.9305, 1.1618])                0\n",
      "116. tensor([3.3876, 1.3766])                0\n",
      "117. tensor([3.2880, 1.2847])                0\n",
      "118. tensor([2.8043, 1.1113])                1\n",
      "119. tensor([2.1756, 0.7624])                0\n",
      "120. tensor([2.3617, 0.8352])                0\n",
      "121. tensor([1.9737, 0.6456])                1\n",
      "122. tensor([2.0910, 0.7339])                0\n",
      "123. tensor([2.4605, 0.9435])                0\n",
      "124. tensor([2.4559, 0.9091])                0\n",
      "125. tensor([2.9647, 1.0931])                0\n",
      "126. tensor([2.3099, 0.8474])                1\n",
      "127. tensor([2.0035, 0.8911])                1\n",
      "128. tensor([2.9933, 1.2143])                0\n",
      "129. tensor([2.7858, 1.0352])                0\n",
      "130. tensor([2.8851, 1.0638])                0\n",
      "131. tensor([2.1449, 0.7394])                0\n",
      "132. tensor([3.0202, 1.1179])                0\n",
      "133. tensor([2.8673, 1.0606])                0\n",
      "134. tensor([2.8080, 1.0321])                0\n",
      "135. tensor([2.6700, 0.9889])                0\n",
      "136. tensor([3.2239, 1.2410])                0\n",
      "137. tensor([2.6658, 1.0317])                0\n",
      "138. tensor([2.7211, 1.0155])                1\n",
      "139. tensor([2.5078, 0.8946])                0\n",
      "140. tensor([2.9110, 1.0962])                0\n",
      "141. tensor([2.7198, 0.9893])                0\n",
      "142. tensor([2.4509, 0.9064])                0\n",
      "143. tensor([2.4531, 0.8932])                0\n",
      "144. tensor([2.6816, 0.9508])                0\n",
      "145. tensor([2.1313, 0.8617])                1\n",
      "146. tensor([2.3108, 0.8271])                0\n",
      "147. tensor([2.4685, 0.9298])                1\n",
      "148. tensor([2.7425, 1.0164])                0\n",
      "149. tensor([2.7950, 1.0746])                0\n",
      "150. tensor([3.0817, 1.2094])                0\n",
      "151. tensor([2.4242, 0.8922])                0\n",
      "152. tensor([2.9020, 1.0932])                0\n",
      "153. tensor([2.5854, 0.9319])                0\n",
      "154. tensor([2.4798, 0.8941])                0\n",
      "155. tensor([2.5456, 0.9333])                0\n",
      "156. tensor([2.5664, 0.9401])                0\n",
      "157. tensor([1.9667, 0.6379])                0\n",
      "158. tensor([2.4264, 0.8693])                0\n",
      "159. tensor([2.7764, 1.0411])                0\n",
      "160. tensor([2.8197, 1.1313])                1\n",
      "161. tensor([3.4006, 1.3780])                1\n",
      "162. tensor([3.5093, 1.4076])                0\n",
      "163. tensor([3.2246, 1.2594])                0\n",
      "164. tensor([1.8915, 0.6352])                0\n",
      "165. tensor([2.1694, 0.8337])                1\n",
      "166. tensor([2.6623, 0.9876])                0\n",
      "167. tensor([3.0975, 1.2388])                1\n",
      "168. tensor([2.3963, 0.8523])                0\n",
      "169. tensor([1.9218, 0.6440])                0\n",
      "170. tensor([2.9093, 1.1159])                1\n",
      "171. tensor([2.2355, 0.7968])                0\n",
      "172. tensor([2.3654, 0.8329])                0\n",
      "173. tensor([2.9576, 1.0730])                0\n",
      "174. tensor([3.1460, 1.2320])                0\n",
      "175. tensor([2.4571, 0.9739])                0\n",
      "176. tensor([3.2073, 1.3187])                1\n",
      "177. tensor([2.3460, 0.8586])                1\n",
      "178. tensor([2.7395, 1.0270])                0\n",
      "179. tensor([3.8598, 1.5997])                0\n",
      "180. tensor([2.9240, 1.1430])                0\n",
      "181. tensor([3.4657, 1.4158])                0\n",
      "182. tensor([2.7595, 1.1091])                0\n",
      "183. tensor([3.0412, 1.1516])                0\n",
      "184. tensor([2.2752, 0.8696])                1\n",
      "185. tensor([3.1212, 1.2196])                0\n",
      "186. tensor([2.7477, 0.9994])                0\n",
      "187. tensor([2.7327, 1.0168])                0\n",
      "188. tensor([3.1668, 1.2491])                0\n",
      "189. tensor([3.0723, 1.2182])                0\n",
      "190. tensor([1.8866, 0.6594])                1\n",
      "191. tensor([2.6372, 1.0210])                1\n",
      "192. tensor([2.8644, 1.1153])                0\n",
      "193. tensor([2.0686, 0.6886])                0\n",
      "194. tensor([2.2299, 0.8263])                0\n",
      "195. tensor([2.5316, 0.9917])                0\n",
      "196. tensor([2.4790, 0.9029])                0\n",
      "197. tensor([2.6411, 0.9950])                0\n",
      "198. tensor([2.1458, 0.7616])                0\n",
      "199. tensor([3.0283, 1.1635])                1\n",
      "200. tensor([2.7224, 1.0406])                0\n",
      "201. tensor([2.0778, 0.6936])                0\n",
      "202. tensor([3.9197, 1.6700])                0\n",
      "203. tensor([3.1351, 1.2556])                1\n",
      "204. tensor([3.3972, 1.2818])                0\n",
      "205. tensor([2.6307, 0.9826])                0\n",
      "206. tensor([2.6136, 0.9698])                0\n",
      "207. tensor([2.1999, 0.7466])                0\n",
      "208. tensor([2.4907, 0.9480])                0\n",
      "209. tensor([3.2280, 1.2296])                0\n",
      "210. tensor([2.3198, 0.8348])                0\n",
      "211. tensor([2.7299, 1.0054])                0\n",
      "212. tensor([3.1123, 1.1990])                0\n",
      "213. tensor([2.2187, 0.8210])                0\n",
      "214. tensor([3.0598, 1.1654])                1\n",
      "215. tensor([2.5662, 0.9472])                0\n",
      "216. tensor([3.1308, 1.2630])                0\n",
      "217. tensor([1.2109, 1.3045])                1\n",
      "218. tensor([2.7579, 1.0443])                0\n",
      "219. tensor([2.8240, 1.0435])                0\n",
      "220. tensor([2.8186, 1.0979])                0\n",
      "221. tensor([2.6051, 0.9156])                0\n",
      "222. tensor([2.7555, 1.0590])                1\n",
      "223. tensor([2.9951, 1.2023])                1\n",
      "224. tensor([2.6885, 1.0245])                1\n",
      "225. tensor([2.2798, 0.8615])                0\n",
      "226. tensor([2.9606, 1.2062])                1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227. tensor([2.9632, 1.1481])                0\n",
      "228. tensor([2.7430, 1.0024])                0\n",
      "229. tensor([2.9587, 1.1020])                0\n",
      "230. tensor([3.1161, 1.2006])                1\n",
      "231. tensor([2.2415, 0.7939])                0\n",
      "232. tensor([3.6843, 1.4380])                0\n",
      "233. tensor([2.1646, 0.7903])                0\n",
      "234. tensor([3.5767, 1.4449])                0\n",
      "235. tensor([2.6231, 0.9686])                0\n",
      "236. tensor([2.4702, 0.9688])                0\n",
      "237. tensor([1.8478, 0.6227])                0\n",
      "238. tensor([3.1755, 1.2758])                1\n",
      "239. tensor([2.9411, 1.1433])                0\n",
      "240. tensor([1.5519, 0.5265])                0\n",
      "241. tensor([2.3538, 0.8309])                0\n",
      "242. tensor([3.2478, 1.2210])                1\n",
      "243. tensor([0.7961, 1.0817])                0\n",
      "244. tensor([2.7096, 1.0096])                0\n",
      "245. tensor([2.2406, 0.8400])                1\n",
      "246. tensor([2.9397, 1.1096])                0\n",
      "247. tensor([2.5853, 0.9459])                0\n",
      "248. tensor([2.9834, 1.2015])                0\n",
      "249. tensor([2.2673, 0.8602])                0\n",
      "250. tensor([2.9647, 1.1537])                1\n",
      "251. tensor([2.9050, 1.0735])                0\n",
      "252. tensor([2.8156, 1.1267])                0\n",
      "253. tensor([2.0399, 0.6731])                0\n",
      "254. tensor([2.8799, 1.0810])                0\n",
      "255. tensor([2.1016, 0.6903])                0\n",
      "256. tensor([2.9556, 1.2276])                1\n",
      "257. tensor([2.8878, 1.0800])                0\n",
      "258. tensor([3.1019, 1.1708])                0\n",
      "259. tensor([2.5398, 0.9380])                1\n",
      "260. tensor([2.7866, 1.0783])                0\n",
      "261. tensor([3.0176, 1.1770])                1\n",
      "262. tensor([1.8803, 0.6316])                0\n",
      "263. tensor([3.0321, 1.1378])                0\n",
      "264. tensor([2.3217, 0.8218])                0\n",
      "265. tensor([2.6230, 0.9617])                0\n",
      "266. tensor([3.3406, 1.3709])                0\n",
      "267. tensor([2.1832, 0.8135])                0\n",
      "268. tensor([2.1535, 0.7199])                0\n",
      "269. tensor([2.3362, 0.8305])                0\n",
      "270. tensor([3.6035, 1.3917])                0\n",
      "271. tensor([2.3366, 0.9135])                0\n",
      "272. tensor([3.4861, 1.3560])                1\n",
      "273. tensor([2.4175, 0.9289])                0\n",
      "274. tensor([2.1224, 0.7644])                0\n",
      "275. tensor([3.0639, 1.1859])                1\n",
      "276. tensor([2.6741, 1.0111])                0\n",
      "277. tensor([2.9991, 1.1530])                0\n",
      "278. tensor([2.7526, 1.0882])                1\n",
      "279. tensor([2.5207, 0.9249])                0\n",
      "280. tensor([2.1943, 0.7773])                0\n",
      "281. tensor([2.9000, 1.1291])                0\n",
      "282. tensor([2.5205, 0.9367])                0\n",
      "283. tensor([2.8123, 1.0993])                0\n",
      "284. tensor([2.6534, 0.9981])                1\n",
      "285. tensor([3.1078, 1.2080])                0\n",
      "286. tensor([3.0928, 1.2253])                0\n",
      "287. tensor([2.2087, 0.7487])                0\n",
      "288. tensor([3.0839, 1.2329])                0\n",
      "289. tensor([2.7135, 1.0489])                0\n",
      "290. tensor([2.6767, 1.0308])                0\n",
      "291. tensor([2.6085, 0.9746])                1\n",
      "292. tensor([1.2534, 0.8582])                0\n",
      "293. tensor([2.9289, 1.1623])                1\n",
      "294. tensor([2.1917, 0.8831])                0\n",
      "295. tensor([3.2159, 1.2262])                0\n",
      "296. tensor([2.8346, 1.1344])                0\n",
      "297. tensor([3.1806, 1.2635])                0\n",
      "298. tensor([2.7777, 1.0200])                1\n",
      "299. tensor([3.4827, 1.4406])                0\n",
      "300. tensor([2.4256, 0.9058])                0\n",
      "301. tensor([2.6901, 0.9728])                0\n",
      "302. tensor([2.5184, 0.9120])                0\n",
      "303. tensor([2.8293, 1.0771])                1\n",
      "304. tensor([2.8581, 1.0493])                0\n",
      "305. tensor([2.6160, 1.0185])                1\n",
      "306. tensor([3.2005, 1.2629])                1\n",
      "307. tensor([2.7354, 1.0414])                0\n",
      "308. tensor([3.2922, 1.2722])                0\n",
      "309. tensor([2.5661, 0.9375])                0\n",
      "310. tensor([2.1829, 0.7289])                0\n",
      "311. tensor([3.2597, 1.2931])                0\n",
      "312. tensor([3.0956, 1.1744])                0\n",
      "313. tensor([2.4630, 1.0299])                0\n",
      "314. tensor([3.4431, 1.3662])                0\n",
      "315. tensor([2.8818, 1.0508])                0\n",
      "316. tensor([3.1635, 1.2467])                0\n",
      "317. tensor([2.6053, 0.9625])                0\n",
      "318. tensor([2.7145, 1.0098])                0\n",
      "319. tensor([2.7231, 1.0591])                0\n",
      "320. tensor([2.2000, 0.8112])                1\n",
      "321. tensor([2.4281, 0.8389])                0\n",
      "322. tensor([2.8190, 1.0867])                1\n",
      "323. tensor([2.4449, 0.8894])                0\n",
      "324. tensor([3.1790, 1.2203])                0\n",
      "325. tensor([2.5613, 0.9559])                0\n",
      "326. tensor([2.7939, 1.1062])                0\n",
      "327. tensor([3.0454, 1.1924])                0\n",
      "328. tensor([2.1790, 0.7487])                0\n",
      "329. tensor([2.5324, 0.9009])                0\n",
      "330. tensor([3.1207, 1.1870])                0\n",
      "331. tensor([2.3137, 0.8250])                0\n",
      "332. tensor([2.7801, 1.0148])                1\n",
      "333. tensor([3.0804, 1.2192])                0\n",
      "334. tensor([3.2447, 1.2204])                1\n",
      "335. tensor([2.9423, 1.1987])                0\n",
      "336. tensor([2.2066, 0.7778])                1\n",
      "337. tensor([2.5225, 0.9313])                0\n",
      "338. tensor([2.4116, 0.8508])                0\n",
      "339. tensor([2.3150, 0.8227])                0\n",
      "340. tensor([3.1882, 1.2238])                1\n",
      "341. tensor([3.0029, 1.1345])                0\n",
      "342. tensor([2.9622, 1.1058])                0\n",
      "343. tensor([2.0206, 0.6624])                0\n",
      "344. tensor([3.0047, 1.1703])                0\n",
      "345. tensor([2.6730, 0.9660])                0\n",
      "346. tensor([3.1705, 1.1667])                1\n",
      "347. tensor([3.2674, 1.3156])                0\n",
      "348. tensor([2.3613, 0.8109])                0\n",
      "349. tensor([2.4440, 0.8714])                0\n",
      "350. tensor([2.5462, 0.9465])                0\n",
      "351. tensor([2.5513, 0.9100])                0\n",
      "352. tensor([2.6860, 1.0327])                0\n",
      "353. tensor([2.8921, 1.1067])                1\n",
      "354. tensor([2.7142, 1.0652])                0\n",
      "355. tensor([1.8608, 0.6190])                0\n",
      "356. tensor([1.9688, 0.6316])                0\n",
      "357. tensor([2.5645, 0.9518])                0\n",
      "358. tensor([2.8310, 1.0366])                0\n",
      "359. tensor([3.5272, 1.4143])                0\n",
      "360. tensor([2.8381, 1.0254])                0\n",
      "361. tensor([3.1798, 1.2879])                0\n",
      "362. tensor([2.8294, 1.0594])                0\n",
      "363. tensor([2.7062, 1.0166])                0\n",
      "364. tensor([3.6460, 1.4127])                0\n",
      "365. tensor([2.7950, 0.9903])                1\n",
      "366. tensor([1.9558, 0.6997])                0\n",
      "367. tensor([2.7549, 1.0825])                0\n",
      "368. tensor([2.8667, 1.0952])                0\n",
      "369. tensor([2.8416, 1.1467])                0\n",
      "370. tensor([3.2336, 1.2855])                1\n",
      "371. tensor([2.5489, 0.9427])                1\n",
      "372. tensor([3.7304, 1.5773])                0\n",
      "373. tensor([2.8048, 1.0168])                0\n",
      "374. tensor([2.2686, 0.8730])                1\n",
      "375. tensor([2.3617, 0.8584])                0\n",
      "376. tensor([2.7035, 0.9790])                0\n",
      "377. tensor([3.0347, 1.1980])                1\n",
      "378. tensor([3.3297, 1.3369])                0\n",
      "379. tensor([3.1698, 1.2841])                0\n",
      "380. tensor([2.4949, 0.9809])                1\n",
      "381. tensor([2.5468, 0.9540])                0\n",
      "382. tensor([3.0393, 1.1654])                1\n",
      "383. tensor([2.8640, 1.1110])                0\n",
      "384. tensor([2.7188, 1.0653])                0\n",
      "385. tensor([2.6558, 0.9470])                0\n",
      "386. tensor([2.7437, 1.0566])                0\n",
      "387. tensor([2.8124, 1.1067])                1\n",
      "388. tensor([2.5563, 0.9215])                0\n",
      "389. tensor([2.5101, 0.9004])                0\n",
      "390. tensor([2.5754, 0.9742])                0\n",
      "391. tensor([2.3475, 0.8230])                0\n",
      "392. tensor([2.3858, 0.8872])                0\n",
      "393. tensor([2.4109, 1.0355])                0\n",
      "394. tensor([2.7492, 0.9812])                0\n",
      "395. tensor([2.7128, 1.0093])                0\n",
      "396. tensor([2.9935, 1.1911])                1\n",
      "397. tensor([2.5011, 0.8898])                0\n",
      "398. tensor([2.4022, 0.9032])                1\n",
      "399. tensor([3.3386, 1.2558])                0\n",
      "400. tensor([2.8360, 1.0512])                0\n",
      "401. tensor([2.1641, 0.7260])                0\n",
      "402. tensor([3.0764, 1.1412])                1\n",
      "403. tensor([3.0480, 1.1623])                0\n",
      "404. tensor([3.3730, 1.3314])                0\n",
      "405. tensor([2.7817, 1.0744])                0\n",
      "406. tensor([2.6275, 0.9821])                0\n",
      "407. tensor([2.7566, 0.9928])                0\n",
      "408. tensor([2.0344, 0.7265])                0\n",
      "409. tensor([2.9944, 1.1230])                0\n",
      "410. tensor([2.6770, 1.0275])                0\n",
      "411. tensor([3.2971, 1.2212])                0\n",
      "412. tensor([2.8560, 1.1070])                0\n",
      "413. tensor([3.1186, 1.1864])                0\n",
      "414. tensor([2.7792, 1.0316])                0\n",
      "415. tensor([2.7341, 0.9917])                0\n",
      "416. tensor([2.1931, 0.7626])                0\n",
      "417. tensor([2.5638, 0.9708])                0\n",
      "418. tensor([2.8651, 1.0972])                0\n",
      "419. tensor([2.3113, 0.8133])                0\n",
      "420. tensor([2.7181, 1.0231])                0\n",
      "421. tensor([2.3035, 0.8565])                0\n",
      "422. tensor([3.6830, 1.4421])                0\n",
      "423. tensor([3.2788, 1.3871])                1\n",
      "424. tensor([2.4663, 0.8659])                0\n",
      "425. tensor([3.0016, 1.1181])                0\n",
      "426. tensor([3.0778, 1.1199])                0\n",
      "427. tensor([2.1484, 0.7246])                0\n",
      "428. tensor([2.7086, 1.0771])                1\n",
      "429. tensor([2.1795, 0.7579])                0\n",
      "430. tensor([2.2800, 0.8174])                0\n",
      "431. tensor([2.9190, 1.1232])                1\n",
      "432. tensor([2.5333, 0.9377])                0\n",
      "433. tensor([3.1539, 1.2305])                0\n",
      "434. tensor([3.3200, 1.2983])                0\n",
      "435. tensor([2.3651, 0.8086])                0\n",
      "436. tensor([2.2138, 0.7878])                0\n",
      "437. tensor([2.1980, 0.7579])                0\n",
      "438. tensor([2.3875, 0.8922])                0\n",
      "439. tensor([3.3165, 1.3345])                0\n",
      "440. tensor([3.1307, 1.2659])                0\n",
      "441. tensor([2.8753, 1.1179])                0\n",
      "442. tensor([3.4060, 1.3666])                0\n",
      "443. tensor([2.6731, 0.9764])                0\n",
      "444. tensor([2.6164, 1.0407])                0\n",
      "445. tensor([2.1634, 0.8035])                0\n",
      "446. tensor([3.8001, 1.5381])                0\n",
      "447. tensor([2.7674, 1.0368])                0\n",
      "448. tensor([2.8120, 1.0534])                0\n",
      "449. tensor([2.6679, 1.0292])                0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450. tensor([4.0186, 1.7073])                1\n",
      "451. tensor([2.0148, 0.7130])                0\n",
      "452. tensor([3.1900, 1.2285])                0\n",
      "453. tensor([2.4149, 0.9315])                0\n",
      "454. tensor([3.6619, 1.4860])                0\n",
      "455. tensor([2.1319, 0.9570])                0\n",
      "456. tensor([2.1971, 0.7540])                0\n",
      "457. tensor([2.4400, 0.8616])                0\n",
      "458. tensor([2.8663, 1.1518])                0\n",
      "459. tensor([2.7361, 1.0660])                0\n",
      "460. tensor([1.9498, 0.7050])                0\n",
      "461. tensor([2.5786, 0.9226])                1\n",
      "462. tensor([2.5860, 0.9348])                0\n",
      "463. tensor([2.5020, 0.8839])                0\n",
      "464. tensor([2.7675, 1.0672])                1\n",
      "465. tensor([2.6649, 0.9717])                0\n",
      "466. tensor([3.0565, 1.1992])                0\n",
      "467. tensor([2.9415, 1.0520])                0\n",
      "468. tensor([2.4642, 0.8948])                0\n",
      "469. tensor([2.4725, 0.9104])                0\n",
      "470. tensor([2.9805, 1.1052])                0\n",
      "471. tensor([2.9907, 1.1739])                0\n",
      "472. tensor([2.3156, 0.8456])                0\n",
      "473. tensor([2.7560, 1.0075])                0\n",
      "474. tensor([2.3759, 0.8532])                0\n",
      "475. tensor([2.6479, 0.9649])                1\n",
      "476. tensor([3.1138, 1.2571])                0\n",
      "477. tensor([3.3614, 1.2751])                1\n",
      "478. tensor([2.8852, 1.0983])                1\n",
      "479. tensor([2.9376, 1.1390])                0\n",
      "480. tensor([3.1176, 1.2419])                0\n",
      "481. tensor([1.3526, 0.8934])                1\n",
      "482. tensor([3.2135, 1.3055])                0\n",
      "483. tensor([2.9677, 1.1228])                0\n",
      "484. tensor([3.2852, 1.3083])                0\n",
      "485. tensor([2.4344, 0.8773])                0\n",
      "486. tensor([2.9009, 1.1069])                0\n",
      "487. tensor([3.2002, 1.2194])                1\n",
      "488. tensor([2.3321, 0.8199])                0\n",
      "489. tensor([2.7633, 1.0466])                0\n",
      "490. tensor([2.7339, 1.0298])                0\n",
      "491. tensor([2.6342, 0.9522])                0\n",
      "492. tensor([3.6696, 1.4854])                1\n",
      "493. tensor([2.6238, 0.9913])                0\n",
      "494. tensor([2.4342, 0.8921])                0\n",
      "495. tensor([2.0835, 0.7211])                0\n",
      "496. tensor([2.8000, 1.0619])                0\n",
      "497. tensor([4.0171, 1.6798])                0\n",
      "498. tensor([2.6326, 0.9698])                0\n",
      "499. tensor([3.1901, 1.2428])                0\n",
      "500. tensor([2.7142, 0.9973])                0\n",
      "501. tensor([2.4535, 0.9468])                0\n",
      "502. tensor([2.6939, 0.9796])                1\n",
      "503. tensor([2.8211, 1.0699])                0\n",
      "504. tensor([3.0512, 1.1750])                0\n",
      "505. tensor([2.7807, 1.0905])                1\n",
      "506. tensor([2.4233, 0.8439])                0\n",
      "507. tensor([2.4889, 0.8928])                0\n",
      "508. tensor([2.8004, 1.0688])                1\n",
      "509. tensor([3.6254, 1.3667])                0\n",
      "510. tensor([2.6634, 0.9927])                1\n",
      "511. tensor([3.1040, 1.2273])                0\n",
      "512. tensor([2.9222, 1.1199])                1\n",
      "513. tensor([3.4722, 1.4081])                1\n",
      "514. tensor([2.8147, 1.0195])                0\n",
      "515. tensor([3.2863, 1.2680])                1\n",
      "516. tensor([3.4840, 1.4314])                1\n",
      "517. tensor([2.8228, 1.1502])                1\n",
      "518. tensor([2.8422, 1.0685])                0\n",
      "519. tensor([2.4283, 0.8619])                0\n",
      "520. tensor([2.3868, 0.8453])                0\n",
      "521. tensor([2.7781, 1.0605])                0\n",
      "522. tensor([3.3521, 1.3933])                0\n",
      "523. tensor([2.9736, 1.1509])                0\n",
      "524. tensor([2.9547, 1.1446])                0\n",
      "525. tensor([2.2947, 0.7721])                0\n",
      "526. tensor([2.9346, 1.1333])                0\n",
      "527. tensor([3.1695, 1.2299])                0\n",
      "528. tensor([3.0132, 1.1823])                1\n",
      "529. tensor([2.4417, 0.9470])                0\n",
      "530. tensor([2.2000, 0.8382])                0\n",
      "531. tensor([3.0418, 1.1475])                0\n",
      "532. tensor([2.9548, 1.1361])                0\n",
      "533. tensor([2.4239, 0.8255])                0\n",
      "534. tensor([2.6100, 1.0466])                0\n",
      "535. tensor([1.9533, 0.6394])                0\n",
      "536. tensor([3.4029, 1.3962])                0\n",
      "537. tensor([2.6127, 1.0155])                0\n",
      "538. tensor([2.6696, 1.0141])                0\n",
      "539. tensor([2.7224, 1.0337])                0\n",
      "540. tensor([3.6948, 1.5319])                0\n",
      "541. tensor([2.5710, 0.9728])                0\n",
      "542. tensor([1.4122, 1.0372])                1\n",
      "543. tensor([2.5229, 0.9870])                1\n",
      "544. tensor([1.8253, 0.6213])                0\n",
      "545. tensor([2.8083, 1.1171])                0\n",
      "546. tensor([3.0624, 1.1646])                0\n",
      "547. tensor([3.0111, 1.1483])                0\n",
      "548. tensor([1.7813, 0.6807])                1\n",
      "549. tensor([2.5778, 1.0061])                1\n",
      "550. tensor([2.3598, 0.8073])                0\n",
      "551. tensor([2.7184, 1.0139])                0\n",
      "552. tensor([2.6807, 0.9888])                0\n",
      "553. tensor([2.9285, 1.1327])                0\n",
      "554. tensor([2.9807, 1.1543])                0\n",
      "555. tensor([2.5859, 0.9062])                0\n",
      "556. tensor([2.9735, 1.0798])                0\n",
      "557. tensor([2.7141, 1.0431])                0\n",
      "558. tensor([2.0776, 0.7086])                0\n",
      "559. tensor([2.4534, 0.8506])                0\n",
      "560. tensor([2.8056, 1.0451])                1\n",
      "561. tensor([2.7053, 1.0026])                0\n",
      "562. tensor([2.9170, 1.1157])                0\n",
      "563. tensor([2.4261, 0.8707])                0\n",
      "564. tensor([1.9981, 0.6795])                0\n",
      "565. tensor([2.6759, 1.0149])                0\n",
      "566. tensor([2.1891, 0.7740])                0\n",
      "567. tensor([2.3217, 1.0293])                1\n",
      "568. tensor([2.2410, 0.7854])                0\n",
      "569. tensor([2.7837, 1.0197])                0\n",
      "570. tensor([3.2162, 1.3098])                1\n",
      "571. tensor([2.9997, 1.2132])                1\n",
      "572. tensor([2.5311, 0.8863])                0\n",
      "573. tensor([2.9771, 1.1278])                0\n",
      "574. tensor([2.7026, 0.9801])                0\n",
      "575. tensor([2.9982, 1.1404])                0\n",
      "576. tensor([2.4606, 0.8869])                0\n",
      "577. tensor([3.3708, 1.3497])                0\n",
      "578. tensor([2.8644, 1.1082])                0\n",
      "579. tensor([3.2404, 1.2663])                0\n",
      "580. tensor([2.4803, 0.8631])                0\n",
      "581. tensor([2.7438, 1.0493])                0\n",
      "582. tensor([3.2106, 1.2176])                0\n",
      "583. tensor([2.7376, 1.0529])                0\n",
      "584. tensor([2.5087, 0.9566])                0\n",
      "585. tensor([2.3967, 0.8326])                0\n",
      "586. tensor([2.6407, 1.0291])                1\n",
      "587. tensor([2.9494, 1.1487])                1\n",
      "588. tensor([2.3944, 0.8779])                0\n",
      "589. tensor([2.5636, 0.9032])                0\n",
      "590. tensor([2.5067, 0.8635])                1\n",
      "591. tensor([3.1396, 1.2824])                0\n",
      "592. tensor([2.9148, 1.1362])                0\n",
      "593. tensor([2.9294, 1.1046])                0\n",
      "594. tensor([2.9563, 1.1322])                0\n",
      "595. tensor([2.6906, 0.9639])                0\n",
      "596. tensor([2.3707, 0.8786])                0\n",
      "597. tensor([1.9733, 0.6986])                0\n",
      "598. tensor([1.9349, 0.6561])                0\n",
      "599. tensor([2.0248, 0.6712])                0\n",
      "600. tensor([3.0335, 1.2136])                1\n",
      "601. tensor([2.3476, 0.8337])                0\n",
      "602. tensor([3.0973, 1.1859])                0\n",
      "603. tensor([2.5520, 0.9180])                0\n",
      "604. tensor([2.1366, 0.7823])                0\n",
      "605. tensor([3.2976, 1.2726])                0\n",
      "606. tensor([2.7835, 1.0953])                0\n",
      "607. tensor([3.3576, 1.3518])                0\n",
      "608. tensor([2.7141, 0.9616])                0\n",
      "609. tensor([2.7966, 1.0334])                1\n",
      "610. tensor([2.1821, 0.7456])                0\n",
      "611. tensor([2.5911, 0.9565])                0\n",
      "612. tensor([2.8827, 1.0813])                0\n",
      "613. tensor([2.8991, 1.0537])                0\n",
      "614. tensor([2.4031, 0.8403])                0\n",
      "615. tensor([3.3160, 1.3336])                0\n",
      "616. tensor([2.7524, 1.0398])                0\n",
      "617. tensor([3.3225, 1.3910])                0\n",
      "618. tensor([2.1760, 0.7569])                0\n",
      "619. tensor([2.6000, 0.9541])                0\n",
      "620. tensor([2.1462, 0.8213])                0\n",
      "621. tensor([2.8586, 1.0553])                0\n",
      "622. tensor([2.5797, 0.9477])                0\n",
      "623. tensor([2.7948, 1.0405])                1\n",
      "624. tensor([2.8678, 1.0648])                1\n",
      "625. tensor([2.5985, 0.9945])                0\n",
      "626. tensor([3.0233, 1.1511])                0\n",
      "627. tensor([2.8766, 1.1038])                0\n",
      "628. tensor([2.7748, 1.0813])                1\n",
      "629. tensor([2.7791, 1.0024])                0\n",
      "630. tensor([2.2830, 0.7951])                0\n",
      "631. tensor([2.4104, 0.8954])                1\n",
      "632. tensor([2.2762, 0.8241])                0\n",
      "633. tensor([2.8872, 1.1185])                1\n",
      "634. tensor([2.7000, 1.0260])                0\n",
      "635. tensor([2.5663, 0.9116])                1\n",
      "636. tensor([2.5381, 0.9858])                0\n",
      "637. tensor([3.0359, 1.1396])                0\n",
      "638. tensor([2.7712, 1.0418])                0\n",
      "639. tensor([3.3571, 1.3443])                0\n",
      "640. tensor([3.2086, 1.2442])                0\n",
      "641. tensor([2.3380, 0.8388])                0\n",
      "642. tensor([3.0666, 1.1388])                0\n",
      "643. tensor([2.2816, 0.7863])                0\n",
      "644. tensor([3.0182, 1.1742])                1\n",
      "645. tensor([2.2003, 0.7451])                0\n",
      "646. tensor([3.1755, 1.2468])                0\n",
      "647. tensor([2.9945, 1.1360])                0\n",
      "648. tensor([2.5074, 0.8844])                0\n",
      "649. tensor([1.2731, 1.0680])                1\n",
      "650. tensor([3.0586, 1.2303])                0\n",
      "651. tensor([3.6538, 1.4867])                1\n",
      "652. tensor([3.1354, 1.2421])                1\n",
      "653. tensor([2.6307, 0.9469])                0\n",
      "654. tensor([2.8936, 1.1088])                1\n",
      "655. tensor([2.6697, 1.0143])                1\n",
      "656. tensor([3.1136, 1.2078])                0\n",
      "657. tensor([2.4102, 0.8557])                0\n",
      "658. tensor([2.0400, 0.8044])                0\n",
      "659. tensor([1.9535, 0.6754])                0\n",
      "660. tensor([2.5277, 0.9156])                0\n",
      "661. tensor([3.4057, 1.3980])                0\n",
      "662. tensor([2.7007, 1.0006])                0\n",
      "663. tensor([2.6969, 0.9776])                0\n",
      "664. tensor([1.9586, 0.7239])                0\n",
      "665. tensor([2.0847, 0.6970])                0\n",
      "666. tensor([2.7984, 1.1651])                1\n",
      "667. tensor([2.6283, 0.9376])                0\n",
      "668. tensor([2.9369, 1.1457])                0\n",
      "669. tensor([2.9842, 1.1459])                0\n",
      "670. tensor([2.2309, 0.8096])                1\n",
      "671. tensor([2.7051, 1.0039])                0\n",
      "672. tensor([1.3738, 1.5909])                1\n",
      "673. tensor([3.8402, 1.6259])                0\n",
      "674. tensor([2.9267, 1.0843])                0\n",
      "675. tensor([2.6875, 0.9870])                0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676. tensor([2.6168, 0.9986])                1\n",
      "677. tensor([2.6437, 1.0029])                0\n",
      "678. tensor([2.7639, 1.0077])                0\n",
      "679. tensor([3.3274, 1.3524])                0\n",
      "680. tensor([2.8139, 1.0557])                0\n",
      "681. tensor([2.8119, 1.0564])                0\n",
      "682. tensor([2.0502, 0.6880])                0\n",
      "683. tensor([2.8069, 1.0606])                0\n",
      "684. tensor([2.2219, 0.7573])                0\n",
      "685. tensor([3.1191, 1.2348])                0\n",
      "686. tensor([2.2879, 0.8044])                0\n",
      "687. tensor([2.3581, 0.8095])                0\n",
      "688. tensor([2.5775, 1.0003])                0\n",
      "689. tensor([2.8297, 1.0164])                0\n",
      "690. tensor([3.2124, 1.2694])                0\n",
      "691. tensor([2.3610, 0.8959])                0\n",
      "692. tensor([2.6762, 0.9482])                0\n",
      "693. tensor([2.9884, 1.1141])                0\n",
      "694. tensor([2.0563, 0.6987])                0\n",
      "695. tensor([3.4766, 1.3320])                1\n",
      "696. tensor([2.7326, 1.0726])                1\n",
      "697. tensor([2.5413, 0.9343])                0\n",
      "698. tensor([2.9527, 1.1128])                0\n",
      "699. tensor([3.3447, 1.3735])                1\n",
      "700. tensor([3.2762, 1.3327])                0\n",
      "701. tensor([2.5952, 1.0138])                0\n",
      "702. tensor([2.4792, 0.8899])                0\n",
      "703. tensor([3.2179, 1.2387])                0\n",
      "704. tensor([2.4667, 0.9004])                0\n",
      "705. tensor([2.9393, 1.1774])                0\n",
      "706. tensor([2.7351, 1.0616])                1\n",
      "707. tensor([2.9380, 1.1207])                0\n",
      "708. tensor([2.3849, 0.8349])                0\n",
      "709. tensor([2.7709, 1.0460])                0\n",
      "710. tensor([2.7856, 1.0055])                1\n",
      "711. tensor([2.8863, 1.0431])                0\n",
      "712. tensor([2.5089, 0.9155])                0\n",
      "713. tensor([2.9515, 1.1572])                0\n",
      "714. tensor([3.3173, 1.3155])                0\n",
      "715. tensor([3.8553, 1.6104])                0\n",
      "716. tensor([3.2464, 1.2736])                1\n",
      "717. tensor([2.5757, 0.9120])                0\n",
      "718. tensor([2.7565, 1.0058])                0\n",
      "719. tensor([2.4046, 1.1807])                0\n",
      "720. tensor([3.1587, 1.2511])                1\n",
      "721. tensor([2.8307, 1.0885])                0\n",
      "722. tensor([2.0177, 0.6753])                0\n",
      "723. tensor([2.5218, 0.9435])                0\n",
      "724. tensor([3.1736, 1.1353])                0\n",
      "725. tensor([3.0970, 1.1931])                0\n",
      "726. tensor([3.2673, 1.2880])                0\n",
      "727. tensor([2.6030, 0.9239])                0\n",
      "728. tensor([2.9246, 1.0933])                0\n",
      "729. tensor([2.5734, 0.9330])                0\n",
      "730. tensor([2.8373, 1.0453])                1\n",
      "731. tensor([1.8148, 0.9859])                0\n",
      "732. tensor([3.4155, 1.3182])                0\n",
      "733. tensor([2.4109, 0.8178])                0\n",
      "734. tensor([2.4178, 0.8895])                0\n",
      "735. tensor([2.6858, 0.9915])                0\n",
      "736. tensor([3.2301, 1.3731])                0\n",
      "737. tensor([2.4933, 0.9404])                0\n",
      "738. tensor([2.3750, 0.8633])                0\n",
      "739. tensor([2.6314, 0.9219])                0\n",
      "740. tensor([3.2276, 1.2503])                0\n",
      "741. tensor([3.1673, 1.1988])                0\n",
      "742. tensor([2.9078, 1.1022])                0\n",
      "743. tensor([2.5927, 0.9660])                0\n",
      "744. tensor([3.1724, 1.2785])                1\n",
      "745. tensor([2.7030, 0.9949])                0\n",
      "746. tensor([3.0682, 1.1416])                0\n",
      "747. tensor([2.4756, 0.8615])                0\n",
      "748. tensor([2.0905, 0.7242])                0\n",
      "749. tensor([2.4010, 0.8754])                0\n",
      "750. tensor([2.7080, 0.9780])                0\n",
      "751. tensor([2.9624, 1.1550])                0\n",
      "\n",
      "613 out of 751 = 81.62% correct\n"
     ]
    }
   ],
   "source": [
    "### Predictions\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(X_test):\n",
    "        y_val = model.forward(data)\n",
    "        print(f'{i+1:2}. {str(y_val):38}  {y_test[i]}')\n",
    "        if y_val.argmax().item() == y_test[i]:\n",
    "            correct += 1\n",
    "\n",
    "print(f'\\n{correct} out of {len(y_test)} = {100*correct/len(y_test):.2f}% correct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 : Heart Attack Risk , 0 : No Heart Attack Risk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the Model\n",
    "torch.save(model.state_dict(), 'Heart_Disease.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
